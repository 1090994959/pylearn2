"""
Cross-validation.
"""
import numpy as np
import warnings
try:
    from sklearn.cross_validation import (KFold, StratifiedKFold, ShuffleSplit,
                                          StratifiedShuffleSplit)
except ImportError:
    warnings.warn("Could not import from sklearn.")


def get_validation_set(train, train_cv, indices):
    """
    Repartition training set into training and validation sets using the
    given subset iterator. Only the first train/test split of train_cv is
    used.

    Parameters
    ----------
    train : array_like
        Indices or boolean mask corresponding to the training set.
    train_cv : subset iterator
        Cross-validation iterator that returns train/test splits of the
        training set.
    indices : bool
        Return train/valid split as arrays of indices instead of boolean
        masks.
    """
    for new_train, new_valid in train_cv:
        if indices:
            return train[new_train], train[new_valid]
        else:
            valid = np.zeros(train.shape, dtype=bool)
            sel = np.where(train)[0][new_valid]
            valid[sel] = True
            train[sel] = False
            return train, valid


class ValidationKFold(KFold):
    """
    K-fold cross-validation. One fold is used for testing, another for
    validation, and the remainder for training.

    Parameters
    ----------
    n : int
        Number of examples.
    n_folds : int
        Number of cross-validation folds. Must be at least 3.
    indices : bool
        Return train/valid/test split as arrays of indices instead of
        boolean masks.
    shuffle : bool
        Whether to shuffle the data before splitting.
    random_state : int, RandomState, or None
        Pseudorandom number seed or generator to use for shuffling.
    """
    def __init__(self, n, n_folds=3, indices=True, shuffle=False,
                 random_state=None):
        if n_folds <= 2:
            raise ValueError("k-fold cross-validation requires at least one " +
                             "train / valid / test split by setting " +
                             "n_folds=3 or more, got " +
                             "n_folds={}.".format(n_folds))
        super(ValidationKFold, self).__init__(n, n_folds, indices, shuffle,
                                              random_state)

    def __iter__(self):
        """
        Return train/valid/test splits. The validation set is generated by
        splitting the training set.
        """
        for train, test in super(KFold, self).__iter__():
            n = len(self.idxs[train])  # works with indices or masks
            train_cv = KFold(n, n_folds=self.n_folds-1, indices=self.indices)
            train, valid = get_validation_set(train, train_cv, self.indices)
            yield train, valid, test


class StratifiedValidationKFold(StratifiedKFold):
    """
    Stratified K-fold cross-validation. One fold is used for testing,
    another for validation, and the remainder for training.

    Parameters
    ----------
    y : array_like
        Labels for examples.
    n_folds : int
        Number of cross-validation folds. Must be at least 3.
    indices : bool
        Return train/valid/test split as arrays of indices instead of
        boolean masks.
    """
    def __init__(self, y, n_folds=3, indices=True):
        if n_folds <= 2:
            raise ValueError("k-fold cross-validation requires at least one " +
                             "train/valid/test split by setting n_folds=3 " +
                             "or more, got n_folds={}.".format(n_folds))
        super(StratifiedValidationKFold, self).__init__(y, n_folds, indices)

    def __iter__(self):
        """
        Return train/valid/test splits. The validation set is generated by
        a stratified split of the training set.
        """
        for train, test in super(StratifiedKFold, self).__iter__():
            y = self.y[train]
            train_cv = StratifiedKFold(y, n_folds=self.n_folds-1,
                                       indices=self.indices)
            train, valid = get_validation_set(train, train_cv, self.indices)
            yield train, valid, test


class ValidationShuffleSplit(ShuffleSplit):
    """
    Random permutation cross-validation. The training set is further split
    into training and validation subsets.

    Parameters
    ----------
    n : int
        Number of examples.
    n_iter : int
        Number of shuffle/split iterations.
    test_size : float, int, or None
        If float, should be between 0.0 and 1.0 and represent the
        proportion of the entire dataset to include in the validation
        split. If int, represents the absolute number of validation
        samples. If None, the value is automatically set to the complement
        of train_size + valid_size.
    valid_size : float, int, or None
        If float, should be between 0.0 and 1.0 and represent the
        proportion of the entire dataset to include in the validation
        split. If int, represents the absolute number of validation
        samples. If None, the value is automatically set to match
        test_size.
    train_size : float, int, or None
        If float, should be between 0.0 and 1.0 and represent the
        proportion of the entire dataset to include in the validation
        split. If int, represents the absolute number of validation
        samples. If None, the value is automatically set to the complement
        of valid_size + test_size.
    indices : bool
        Return train/valid/test split as arrays of indices instead of
        boolean masks.
    random_state : int, RandomState, or None
        Pseudorandom number seed or generator to use for shuffling.
    """
    def __init__(self, n, n_iter=10, test_size=0.1, valid_size=None,
                 train_size=None, indices=True, random_state=None):
        super(ValidationShuffleSplit, self).__init__(n, n_iter, test_size,
                                                     train_size, indices,
                                                     random_state)
        if valid_size is None:
            valid_size = self.n_test

        # correct proportion to correspond to a subset of the training set
        if valid_size < 1.0:
            valid_size /= 1.0 - np.true_divide(self.n_test, self.n)
        self.valid_size = valid_size

    def __iter__(self):
        """
        Return train/valid/test splits. The validation set is generated by
        splitting the training set.
        """
        for train, test in super(ShuffleSplit, self).__iter__():
            n = len(np.arange(self.n)[train])  # works with indices or masks
            train_cv = ShuffleSplit(n, test_size=self.valid_size,
                                    indices=self.indices,
                                    random_state=self.random_state)
            train, valid = get_validation_set(train, train_cv, self.indices)
            yield train, valid, test


class StratifiedValidationShuffleSplit(StratifiedShuffleSplit):
    """
    Random stratified permutation cross-validation. The training set is
    further split into training and validation subsets.

    Parameters
    ----------
    y : array_like
        Labels for examples.
    n_iter : int
        Number of shuffle/split iterations.
    test_size : float, int, or None
        If float, should be between 0.0 and 1.0 and represent the
        proportion of the entire dataset to include in the validation
        split. If int, represents the absolute number of validation
        samples. If None, the value is automatically set to the complement
        of train_size + valid_size.
    valid_size : float, int, or None
        If float, should be between 0.0 and 1.0 and represent the
        proportion of the entire dataset to include in the validation
        split. If int, represents the absolute number of validation
        samples. If None, the value is automatically set to match
        test_size.
    train_size : float, int, or None
        If float, should be between 0.0 and 1.0 and represent the
        proportion of the entire dataset to include in the validation
        split. If int, represents the absolute number of validation
        samples. If None, the value is automatically set to the complement
        of valid_size + test_size.
    indices : bool
        Return train/valid/test split as arrays of indices instead of
        boolean masks.
    random_state : int, RandomState, or None
        Pseudorandom number seed or generator to use for shuffling.
    """
    def __init__(self, y, n_iter=10, test_size=0.1, valid_size=None,
                 train_size=None, indices=True, random_state=None):
        super(StratifiedValidationShuffleSplit, self).__init__(y, n_iter,
                                                               test_size,
                                                               train_size,
                                                               indices,
                                                               random_state)
        if valid_size is None:
            valid_size = self.n_test

        # correct proportion to correspond to a subset of the training set
        if valid_size < 1.0:
            valid_size /= 1.0 - np.true_divide(self.n_test, self.n)
        self.valid_size = valid_size

    def __iter__(self):
        """
        Return train/valid/test splits. The validation set is generated by
        a stratified split of the training set.
        """
        for train, test in super(StratifiedShuffleSplit, self).__iter__():
            y = self.y[train]
            train_cv = StratifiedShuffleSplit(y, test_size=self.valid_size,
                                              indices=self.indices,
                                              random_state=self.random_state)
            train, valid = get_validation_set(train, train_cv, self.indices)
            yield train, valid, test
