The files in this directory recreate some of the experiments reported in the
paper

Maxout Networks. Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron
Courville, and Yoshua Bengio. arXiv 2013

If you use the code provided here, please cite that paper.

The experiments reproduced here are as follows:

1) MNIST permutation invariant result

The paper reports obtaining a test set error rate of 0.94%, the best ever
reported (as of this writing) for a multilayer perceptron with no unsupervised
pretraining. To reproduce this result, run

train.py mnist_pi.yaml
train.py mnist_pi_continued.yaml
print_monitor.py mnist_pi_continued.pkl | grep test_y_misclass

You should get 0.009399999999, i.e., 94 mistakes on the test set.

Note: you probably will want to run the above scripts with
THEANO_FLAGS="device=gpu,floatX=float32" for optimal speed, but if you don't
have a GPU it should work without one. I have, however, not tested this case.
The remaining results all require GPU as they are implemented using Alex Krizvhevsky's
CUDA convolution library.

2) MNIST result

The paper reports obtaining a test set error rate of 0.45%, the state of the
art for the MNIST dataset without data augmentation. To reproduce this result,
run:

THEANO_FLAGS="device=gpu,floatX=float32" train.py mnist.yaml
THEANO_FLAGS="device=gpu,floatX=float32" train.py mnist_continued.yaml
THEANO_FLAGS="device=gpu,floatX=float32" python compute_test_err.py mnist_continued.pkl

The final command should print out some progress messages followed by "0.0045"

3) CIFAR-10 result

In the days ahead, we will provide our yaml config files for getting the state of
the art on CIFAR-10.

4) CIFAR-100 result

In the days ahead, we will provide our yaml config files for getting the state of
the art on CIFAR-100.

5) SVHN

In the days ahead, we will provide our yaml config files for getting the state of
the art on SVHN.

