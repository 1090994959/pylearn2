.. _floatX:

========================
Special data type floatX
========================

Intro
=====

Their is a special data type called floatX. It is not a real datatype. It is never present in the theano graph, but their exist constructor and function that will change the floatX to float32 or float64(default) in your graph. You can change the value of floatX when you start the execution of python by setting the environement variables THEANO_GPU=floatX=float{32,64}(case sensitive). You can have the value of floatX with::

      import theano.config as config
      config.floatX

This can help to have the same code run on the cpu in float64 and let it run on the gpu in float32. float32 is the only datatype that is currently supported on the gpu. This can give different result due to rounding error. This option help to compare those difference.

Also, on the cpu, float32 are twice as fast as float64.

Their exist helper function in theano.floatx that simplify using this 
Here is the list of fonction that create/accept tensor of floatX. They are all variant of function that already exist for other datatype.
theano.scalar.Scalar.__init__(dtype)
theano.scalar.floatX
theano.floatx.xscalar
theano.floatx.xvector
theano.floatx.xmatrix
theano.floatx.xrow
theano.floatx.xcol
theano.floatx.xtensor3
theano.floatx.xtensor4
theano.tensor.cast(TensorVariable, dtype)
TensorType.__init__(dtype, broadcastable, name = None, shape=None)

HINT: linear algorythm are less affected by the different precision then non-linear one.
      use numpy.asarray(x,dtype=config.floatX) to cast numpy array to floatX
      numpy.asarray(x,dtype=config.floatX) warn copy only if needed.

WARNING: theano.floatx.set_floatX() exist for our test. Don't use it for something else. If you do, it will make code hard to read and it is a sign that their is something better for you then floatX.
